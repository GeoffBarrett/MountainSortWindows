{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "notebook_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# the code path is two folders up from this notebook + /code\n",
    "core_path = os.path.dirname(notebook_path)\n",
    "code_path = os.path.join(core_path, 'code')\n",
    "\n",
    "sys.path.append(core_path)\n",
    "sys.path.append(code_path)\n",
    "\n",
    "# import the wsl_terminal code\n",
    "from wsl_terminal import BashConfigure\n",
    "from wsl_utils import get_windows_filename, get_ubuntu_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Function to make Running MountainSort Commands Easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_js(pipeline, inputs, outputs, parameters=None, verbose=False):\n",
    "    \"\"\"\n",
    "    This is a function that will run a pipeline given the inputs, outputs, and parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    command = 'ml-run-process %s ' % (pipeline)\n",
    "    \n",
    "    command += '--inputs '\n",
    "\n",
    "    for key, value in inputs.items():\n",
    "        if type(value) != list:\n",
    "            command += '%s:%s ' % (str(key), str(value))\n",
    "        else:\n",
    "            for x in value:\n",
    "                command += '%s:%s ' % (str(key), str(x))\n",
    "\n",
    "    command += '--outputs '\n",
    "\n",
    "    for key, value in outputs.items():\n",
    "        command += '%s:%s ' % (str(key), str(value))\n",
    "\n",
    "    if parameters is not None:\n",
    "        command += '--parameters '\n",
    "\n",
    "        for key, value in parameters.items():\n",
    "            command += '%s:%s ' % (str(key), str(value))\n",
    "\n",
    "    if verbose:\n",
    "        print(command)\n",
    "\n",
    "    cfg = BashConfigure()\n",
    "\n",
    "    cfg.win32_wsl_open_bash(None, [\n",
    "        command,\n",
    "        'sleep 2'  # you can comment this out, I like to visualize the results for a brief moment\n",
    "    ], None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Wavform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-run-process ephys.synthesize_random_waveforms --inputs --outputs waveforms_out:/mnt/e/Apollo_D_Drive/dataset/waveforms_true.mda geometry_out:/mnt/e/Apollo_D_Drive/dataset/geom.csv --parameters upsamplefac:13 M:4 average_peak_amplitude:100 \n"
     ]
    }
   ],
   "source": [
    "# Create some random spike waveforms\n",
    "\n",
    "'''\n",
    "This will create a random spike waveform  4 channels (M), 20 waveforms by default, with\n",
    "upsamplefac*T (T=500 by default) samples, and average peak amplitude of 100.\n",
    "'''\n",
    "\n",
    "pipeline = 'ephys.synthesize_random_waveforms'  # the pipeline that creates the random waveforms\n",
    "\n",
    "# we don't need inputs for this piepline\n",
    "inputs = {}\n",
    "\n",
    "waveforms_out = get_ubuntu_path(r'E:\\Apollo_D_Drive\\dataset\\waveforms_true.mda')\n",
    "geometry_out = get_ubuntu_path(r'E:\\Apollo_D_Drive\\dataset\\geom.csv')\n",
    "\n",
    "# determining where to save our random spike waveform files\n",
    "outputs = {'waveforms_out': waveforms_out,\n",
    "          'geometry_out': geometry_out}\n",
    "\n",
    "# adding an upsampling factor of 13, 4 channels, and avgerage peak amplitude of 100\n",
    "parameters = {'upsamplefac': 13,\n",
    "             'M': 4,\n",
    "             'average_peak_amplitude': 100}\n",
    "\n",
    "run_pipeline_js(pipeline, inputs, outputs, parameters, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Spike Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-run-process ephys.synthesize_random_firings --inputs --outputs firings_out:/mnt/e/Apollo_D_Drive/dataset/firings.mda --parameters duration:600 \n"
     ]
    }
   ],
   "source": [
    "# Create random firing event timings\n",
    "\n",
    "'''\n",
    "This will create an output .mda with a 3xL matrix size. L is the # of events.\n",
    "Second row are time stamps, third row are integer unit labels.\n",
    "'''\n",
    "\n",
    "pipeline = 'ephys.synthesize_random_firings'  # the pipeline that creates the random firings\n",
    "\n",
    "# we don't need inputs for this pipeline\n",
    "inputs = {}\n",
    "\n",
    "firings_out = get_ubuntu_path(r'E:\\Apollo_D_Drive\\dataset\\firings.mda')\n",
    "\n",
    "# determining where to save the firing events file\n",
    "outputs = {'firings_out': firings_out}\n",
    "\n",
    "# adding 600 seconds as the duration\n",
    "parameters = {'duration': 600}\n",
    "\n",
    "run_pipeline_js(pipeline, inputs, outputs, parameters, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Timeseries Data for the Waveforms above at the given spike times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-run-process ephys.synthesize_timeseries --inputs firings:/mnt/e/Apollo_D_Drive/dataset/firings.mda waveforms:/mnt/e/Apollo_D_Drive/dataset/waveforms_true.mda --outputs timeseries_out:/mnt/e/Apollo_D_Drive/dataset/timeseries.mda --parameters duration:600 waveform_upsamplefac:13 noise_level:10 \n"
     ]
    }
   ],
   "source": [
    "# Make a synthetic ephys dataset\n",
    "\n",
    "pipeline = 'ephys.synthesize_timeseries'  # the pipeline that creates the ephys data\n",
    "\n",
    "# we don't need inputs for this pipeline\n",
    "\n",
    "inputs = {'firings': firings_out,\n",
    "         'waveforms': waveforms_out}\n",
    "\n",
    "timeseries_out = get_ubuntu_path(r'E:\\Apollo_D_Drive\\dataset\\timeseries.mda')\n",
    "\n",
    "# determining where to save the timeseries file\n",
    "outputs = {'timeseries_out': timeseries_out}\n",
    "\n",
    "# adding 600 seconds as the duration\n",
    "parameters = {'duration': 600,  # same duration we used for the firing rate\n",
    "             'waveform_upsamplefac': 13,  # the same upsamplefac we used when creating spike waveforms\n",
    "             'noise_level': 10}\n",
    "\n",
    "run_pipeline_js(pipeline, inputs, outputs, parameters, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_command = 'qt-mountainview --raw %s --samplerate 30000 --firings %s' % (timeseries_out, \n",
    "                                                                             firings_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = BashConfigure()\n",
    "cfg.win32_wsl_open_bash(None, [view_command,\n",
    "                               'sleep 2'  # you can comment this out, I like to visualize the results for a brief moment\n",
    "                              ], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
